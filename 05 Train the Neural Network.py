# -*- coding: utf-8 -*-
"""Dense Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17uQw_zYdgZ3CwNTcaNfXmPy809cU-m0m

https://colab.research.google.com/

Data Download Link: https://files.grouplens.org/datasets/movielens/ml-latest-small.zip

Data Source: https://grouplens.org/datasets/movielens/latest/
"""

'''
@article{10.1145/2827872,
author = {Harper, F. Maxwell and Konstan, Joseph A.},
title = {The MovieLens Datasets: History and Context},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2827872},
doi = {10.1145/2827872},
journal = {ACM Trans. Interact. Intell. Syst.},
month = dec,
articleno = {19},
numpages = {19},
keywords = {Datasets, recommendations, ratings, MovieLens}
}
'''

import pandas

ratings_dataframe = pandas.read_csv("../00\ Data/ratings.csv", sep=",")

ratings_dataframe

from sklearn.preprocessing import LabelEncoder

ratings_dataframe["userId"] = LabelEncoder().fit_transform(ratings_dataframe["userId"])

ratings_dataframe

ratings_dataframe.info()

ratings_dataframe["movieId"] = LabelEncoder().fit_transform(ratings_dataframe["movieId"])

ratings_dataframe

!pip install lenskit

from lenskit.algorithms import funksvd

NUMBER_OF_FEATURES = 10

svd_model = funksvd.FunkSVD(NUMBER_OF_FEATURES)

from lenskit import crossfold, util

kFolds = 10

nSamples = 1

from lenskit.batch import predict

def calculate_error(model, train_subset, test_subset):

  svd_model_copy = util.clone(model)

  svd_model_copy.fit(train_subset)

  predictions = predict(svd_model_copy, test_subset)

  return predictions

from lenskit.metrics.predict import rmse

def train_model(dataframe, model):

  train_data = []

  test_data  = []

  subset_errors = []

  partitioned_users = crossfold.partition_users(dataframe, kFolds, crossfold.SampleN(nSamples))

  fold_index = 1

  for train_subset, test_subset in partitioned_users:

    train_data.append(train_subset)

    test_data.append(test_subset)

    predictions = calculate_error(model, train_subset, test_subset)

    error = rmse(predictions["prediction"], predictions["rating"])

    subset_errors.append(error)

    fold_index += 1

    print(fold_index)

  return subset_errors

dataframe_renamed = ratings_dataframe.rename(columns = {
    "userId": "user",
    "movieId": "item",
    "rating": "rating"
})

dataframe_renamed

error = train_model(dataframe_renamed, svd_model)

print(error)

from keras.layers.embeddings import Embedding

class CustomVectorizer:

    def __init__(self, input_dim, output_dim):

        self.input_dim = input_dim

        self.output_dim = output_dim
    
    def __call__(self, input):
   
        input = Embedding(self.input_dim, 
                      self.output_dim)(input)
        return input

from keras import optimizers

from keras.models import Model

from keras import backend 

from keras.layers import Input, Reshape, Dot

def custom_error(actual_y, predicted_y):
    return backend.sqrt(backend.mean(backend.square(predicted_y - actual_y), 
                                     axis=-1))

def neural_network(number_of_inputs_users, number_of_inputs_movies, 
            latent_space_dimension=20):

    input_layer_users = Input(shape=(1,))

    input_layer_movies = Input(shape=(1,))

    vectorized_users = CustomVectorizer(number_of_inputs_users, latent_space_dimension)(input_layer_users)

    vectorized_movies = CustomVectorizer(number_of_inputs_movies, latent_space_dimension)(input_layer_movies)

    latent_feature_vectors_users = Reshape((latent_space_dimension,))(vectorized_users)

    latent_feature_vectors_movies = Reshape((latent_space_dimension,))(vectorized_movies)

    output = Dot(axes=1)([latent_feature_vectors_users, latent_feature_vectors_movies])

    model = Model(inputs=[input_layer_users, 
                          input_layer_movies], outputs=output)
    
    LEARNING_RATE = 0.1

    optimizer = optimizers.SGD(lr= LEARNING_RATE)

    model.compile(optimizer=optimizer, 
                  loss='mean_squared_error',  
                  metrics=[custom_error])

    return model

from sklearn.model_selection import train_test_split

def run_model(model):

    number_of_users = ratings_dataframe['userId'].nunique()

    number_of_movies = ratings_dataframe['movieId'].nunique()

    data = ratings_dataframe[['userId', 'movieId']].values

    target = ratings_dataframe['rating'].values

    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)

    X_train = [X_train[:, 0], X_train[:, 1]]

    X_test = [X_test[:, 0], X_test[:, 1]]

    model_object = model(number_of_users, number_of_movies)

    NUMBER_OF_ITERATIONS = 20

    model_object.fit(x=X_train, y=y_train, epochs=NUMBER_OF_ITERATIONS, verbose=1, validation_split=0.1)

    error = model_object.evaluate(x=X_test, 
                           y=y_test)
    return error

model_error = run_model(neural_network)

print(model_error)