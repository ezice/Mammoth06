# -*- coding: utf-8 -*-
"""Dense Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17uQw_zYdgZ3CwNTcaNfXmPy809cU-m0m

https://colab.research.google.com/

Data Download Link: https://files.grouplens.org/datasets/movielens/ml-latest-small.zip

Data Source: https://grouplens.org/datasets/movielens/latest/
"""

'''
@article{10.1145/2827872,
author = {Harper, F. Maxwell and Konstan, Joseph A.},
title = {The MovieLens Datasets: History and Context},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2827872},
doi = {10.1145/2827872},
journal = {ACM Trans. Interact. Intell. Syst.},
month = dec,
articleno = {19},
numpages = {19},
keywords = {Datasets, recommendations, ratings, MovieLens}
}
'''

import pandas

ratings_dataframe = pandas.read_csv("ratings.csv", sep=",")

ratings_dataframe

from sklearn.preprocessing import LabelEncoder

ratings_dataframe["userId"] = LabelEncoder().fit_transform(ratings_dataframe["userId"])

ratings_dataframe

ratings_dataframe.info()

ratings_dataframe["movieId"] = LabelEncoder().fit_transform(ratings_dataframe["movieId"])

ratings_dataframe

!pip install lenskit

from lenskit.algorithms import funksvd

NUMBER_OF_FEATURES = 10

svd_model = funksvd.FunkSVD(NUMBER_OF_FEATURES)

from lenskit import crossfold, util

kFolds = 10

nSamples = 1

from lenskit.batch import predict

def calculate_error(model, train_subset, test_subset):

  svd_model_copy = util.clone(model)

  svd_model_copy.fit(train_subset)

  predictions = predict(svd_model_copy, test_subset)

  return predictions

from lenskit.metrics.predict import rmse

def train_model(dataframe, model):

  train_data = []

  test_data  = []

  subset_errors = []

  partitioned_users = crossfold.partition_users(dataframe, kFolds, crossfold.SampleN(nSamples))

  fold_index = 1

  for train_subset, test_subset in partitioned_users:

    train_data.append(train_subset)

    test_data.append(test_subset)

    predictions = calculate_error(model, train_subset, test_subset)

    error = rmse(predictions["prediction"], predictions["rating"])

    subset_errors.append(error)

    fold_index += 1

    print(fold_index)

  return subset_errors

dataframe_renamed = ratings_dataframe.rename(columns = {
    "userId": "user",
    "movieId": "item",
    "rating": "rating"
})

dataframe_renamed

error = train_model(dataframe_renamed, svd_model)

print(error)

from keras.layers import Input, Reshape, Dot

from keras.layers.embeddings import Embedding

from keras.models import Model

from keras import optimizers

from keras import backend

class CustomVectorizer:

  def __init__(self, input_dim, output_dim):

    self.input_dim  = input_dim

    self.output_dim = output_dim

  def __call__(self, input):

    input = Embedding(self.input_dim,
                      self.output_dim)(input)

def custom_error(actual_y, predicted_y):

  return backend.sqrt(backend.mean(backend.square(predicted_y - actual_y),
                                   axis = -1))

def neural_network(number_of_inputs_users, 
                   number_of_inputs_movies, 
                   latent_space_dimension = 20):

  input_layer_users  = Input(shape = (1,))

  input_layer_movies = Input(shape = (1,))

  vectorized_inputs_users = CustomVectorizer(number_of_inputs_users,
                                            latent_space_dimension)(input_layer_users)

  vectorized_inputs_movies = CustomVectorizer(number_of_inputs_movies,
                                              latent_space_dimension)(input_layer_movies)

  latent_feature_vectors_users = Reshape((latent_space_dimension,))(vectorized_inputs_users)

  latent_feature_vectors_movies = Reshape((latent_space_dimesion,))(vectorized_inputs_movies)

  output = Dot(axes = 1)([latent_feature_vectors_users, latent_feature_vectors_movies])

  model = Model(inputs  = [input_layer_users, input_layer_movies],
                outputs = output)
  
  LEARNING_RATE = 0.1

  optimizer = optimizers.SGD(lr = LEARNING_RATE)

  model.compile(optimizer = optimizer,
                loss = "mean_squared_error",
                metrics = [custom_error])
  
  return model