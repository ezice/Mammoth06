# -*- coding: utf-8 -*-
"""Dense Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17uQw_zYdgZ3CwNTcaNfXmPy809cU-m0m

https://colab.research.google.com/

Data Download Link: https://files.grouplens.org/datasets/movielens/ml-latest-small.zip

Data Source: https://grouplens.org/datasets/movielens/latest/
"""

'''
@article{10.1145/2827872,
author = {Harper, F. Maxwell and Konstan, Joseph A.},
title = {The MovieLens Datasets: History and Context},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2827872},
doi = {10.1145/2827872},
journal = {ACM Trans. Interact. Intell. Syst.},
month = dec,
articleno = {19},
numpages = {19},
keywords = {Datasets, recommendations, ratings, MovieLens}
}
'''

import pandas
from sklearn.preprocessing import LabelEncoder
from lenskit.algorithms import funksvd
from lenskit import crossfold, util
from lenskit.batch import predict
from lenskit.metrics.predict import rmse
from keras.layers import Embedding
from keras import optimizers
from keras.models import Model
from keras import backend 
from keras.layers import Input, Reshape, Dot
from sklearn.model_selection import train_test_split

ratings_dataframe = pandas.read_csv("00 Data/ratings.csv", sep=",")
# ratings_dataframe

# LabelEncoder is a scikit Learn (sklearn) construct.
# Doc: Encode target labels with value between 0 and n_classes-1.
# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
#      https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-encoding
# These functions are taking the named identifiers and crushing them down to 
# zero-based, no hole indexes.
ratings_dataframe["userId"] = LabelEncoder().fit_transform(ratings_dataframe["userId"])
ratings_dataframe["movieId"] = LabelEncoder().fit_transform(ratings_dataframe["movieId"])

NUMBER_OF_FEATURES = 10
svd_model = funksvd.FunkSVD(NUMBER_OF_FEATURES)

kFolds = 10
nSamples = 1

def calculate_error(model, train_subset, test_subset):
  svd_model_copy = util.clone(model)
  svd_model_copy.fit(train_subset)
  predictions = predict(svd_model_copy, test_subset)
  return predictions

def train_model(dataframe, model):
  train_data = []
  test_data  = []
  subset_errors = []
  partitioned_users = crossfold.partition_users(dataframe, kFolds, crossfold.SampleN(nSamples))
  fold_index = 1

  for train_subset, test_subset in partitioned_users:
    train_data.append(train_subset)
    test_data.append(test_subset)
    predictions = calculate_error(model, train_subset, test_subset)
    error = rmse(predictions["prediction"], predictions["rating"])
    subset_errors.append(error)
    fold_index += 1
    print(fold_index)

  return subset_errors

def main():
  dataframe_renamed = ratings_dataframe.rename(columns = {
      "userId": "user",
      "movieId": "item",
      "rating": "rating"
  })

  dataframe_renamed
  error = train_model(dataframe_renamed, svd_model)
  print(error)
  model_error = run_model(neural_network)
  print(model_error)

class CustomVectorizer:
  def __init__(self, input_dim, output_dim):
    self.input_dim = input_dim
    self.output_dim = output_dim
  
  def __call__(self, input):
    input = Embedding(self.input_dim, 
                  self.output_dim)(input)
    return input

def custom_error(actual_y, predicted_y):
  return backend.sqrt(backend.mean(backend.square(predicted_y - actual_y), 
                                   axis=-1))

def neural_network(number_of_inputs_users, number_of_inputs_movies, 
            latent_space_dimension=20):
  input_layer_users = Input(shape=(1,))
  input_layer_movies = Input(shape=(1,))
  vectorized_users = CustomVectorizer(number_of_inputs_users, latent_space_dimension)(input_layer_users)
  vectorized_movies = CustomVectorizer(number_of_inputs_movies, latent_space_dimension)(input_layer_movies)
  latent_feature_vectors_users = Reshape((latent_space_dimension,))(vectorized_users)
  latent_feature_vectors_movies = Reshape((latent_space_dimension,))(vectorized_movies)
  output = Dot(axes=1)([latent_feature_vectors_users, latent_feature_vectors_movies])
  model = Model(inputs=[input_layer_users, 
                        input_layer_movies], outputs=output)
  
  LEARNING_RATE = 0.1

  optimizer = optimizers.SGD(lr= LEARNING_RATE)
  model.compile(optimizer=optimizer, 
                loss='mean_squared_error',  
                metrics=[custom_error])

  return model

def run_model(model):
  number_of_users = ratings_dataframe['userId'].nunique()
  number_of_movies = ratings_dataframe['movieId'].nunique()
  data = ratings_dataframe[['userId', 'movieId']].values
  target = ratings_dataframe['rating'].values
  X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)
  X_train = [X_train[:, 0], X_train[:, 1]]
  X_test = [X_test[:, 0], X_test[:, 1]]
  model_object = model(number_of_users, number_of_movies)

  NUMBER_OF_ITERATIONS = 20

  model_object.fit(x=X_train, y=y_train, epochs=NUMBER_OF_ITERATIONS, verbose=1, validation_split=0.1)
  error = model_object.evaluate(x=X_test, 
                          y=y_test)
  return error

if __name__ == '__main__':
  main()
